{"./":{"url":"./","title":"Introduction","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 Bourbon的个人博客 关于我 学习清单 关于博客 Bourbon的个人博客 关于我 软件工程本科在读。 现居重庆。 热爱技术，思考和审视世界。 学习清单 Golang 底层原理，常用库 计算机网络 操作系统 数据库：Mysql，Redis Linux 分布式与微服务相关组件 设计模式 关于博客 本博客使用Gitbook开发， 用以记录学习中的收获，以及开发过程中的问题。同时希望分享给有需要的同学。 如有错误，希望联系改正。欢迎交流探讨。 如果本博客能够帮助到您，欢迎打赏。 Github：https://github.com/BourbonWang Email: 1141134779@qq.com Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-23 15:24:35 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/slice.html":{"url":"golang/slice.html","title":"详解 go slice","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 详解 Go slice slice 的存储结构 创建，初始化 空 slice 和 nil slice 对数组进行切片 append() 扩容 copy () slice做函数参数 详解 Go slice 切片 slice 是golang的复合类型，是对数组的补充。数组的长度不可变，go 提供了 slice 作为“动态数组”使用。 slice 底层依赖于数组。且支持通过 append() 向slice中追加元素，长度不够时会动态扩展，通过再次slice切片，可以得到得到更小的slice结构，可以迭代、遍历等。 slice 的存储结构 slice的底层结构由3部分组成： pointer：指向底层数组某个元素的指针 Length：slice当前的长度。追加元素时，长度会扩展，最大扩展到Capacity Capacity：底层数组的长度。由于slice的存储依赖于底层数组，所以Capacity也表示了slice最大能扩展到的长度 以上每部分占用8字节，所以一个slice都是24字节。 因此可以知道 golang 创建slice的过程：先创建一个有特定长度和数据类型的底层数组，然后从这个底层数组中选取一部分元素，返回这些元素组成的集合，并将 slice 指向集合中的第一个元素。换句话说，slice自身维护了一个指针属性，指向它底层数组中的某些元素的集合。 a := make([]int,3,5) fmt.Println(a) //[0 0 0] fmt.Println(len(a)) // 3 fmt.Println(cap(a)) // 5 println(a) //[3/5]0xc000094030 上面建立了一个长度为3的切片，它的底层数组长度为5。通过println()可以看出slice的结构，[3/5]表示length 和 capacity， 0xc000094030 表示指向底层数组的指针。这个slice的存储示意图： |---------|----------|--------| | pointer | capacity | length | slice：指向底层数组的第0个元素，长度为3 | | 5 | 3 | |-|-------|----------|--------| \\|/ |-|-----------------| array:长度为5,初始值为0的数组 | 0 | 0 | 0 | 0 | 0 | |---|---|---|---|---| 创建，初始化 直接创建 a := []int{1, 2, 3} //创建len和cap都为3的slice，并赋值 b := []int{9: 3} //创建len和cap都为10的slice，并将index=9的元素赋值3 // [0 0 0 0 0 0 0 0 0 3] 使用make()。可以先为底层数组分配好内存，然后从这个底层数组中再额外生成一个slice并初始化。 slice := make([]int,5) // 创建一个len和cap都为5的slice slice := make([]int,3,5) // 创建一个len=3,cap=5的slice 空 slice 和 nil slice 当声明一个slice，但不做初始化的时候，这个slice就是一个nil slice。 var nil_slice []int nil slice表示它的指向底层数组的指针为nil。也因此，nil slice的长度和容量都为0。 empty slice表示长度为0，容量为0，但却有指向的底层数组，只不过暂时是长度为0的空数组。 empty_slice := make([]int,0) empty_slice := []int{} 无论是nil slice还是empty slice，都可以对它们进行操作，如append()、len()和cap()。 对数组进行切片 对数组切片即为将slice的指针指向该数组，并利用length截取数组某一部分。 numbers := [9]int{0, 1, 2, 3, 4, 5, 6, 7, 8} //len=9 cap=9 slice1 := numbers[1:4] //len=3 cap=8 [1 2 3] slice2 := numbers[4:] //len=5 cap=5 slice=[4 5 6 7 8] 可见，底层数组始终为numbers，cap为剩余可用的数组容量。由于slice的指针指向的数组下标不同，导致了各自可用的cap不同。 因此，对于底层数组容量为k的切片slice[i : j]来说，len = j - i，cap = k - i。 改变切片元素，底层数组同时改变。改变数组元素，与其关联的切片随之改变。 numbers[2] = 10 fmt.Println(slice1) // [1 10 3] slice2[3] = 10 fmt.Println(numbers) // [0 1 10 3 4 5 6 10 8] 当多个slice共享同一个底层数组时，如果修改了某个slice中的元素，实际上修改的是底层数组的值，其它与之关联的slice也会随之改变。当同一个底层数组有很多slice的时候，一切将变得混乱不堪，因为我们不可能记住谁在共享它。所以，需要一种特性，保证各个slice的底层数组互不影响，相关内容见下面的\"扩容\"。 append() 追加元素到slice末尾。len会增加。当追加元素后的slice仍然未达到cap时，append()新元素将赋值给底层数组。当达到cap时，扩容机制将创建新的底层数组。 append()也可以用来合并slice。append()最多允许两个参数，所以一次性只能合并两个slice。但可以将append()作为另一个append()的参数，从而实现多级合并。 s1 := []int{1, 2} s2 := []int{3, 4} s3 := append(s1, s2...) //len=4 cap=4 [1 2 3 4] s4 := append(append(s1, s3...), s2...) //len=8 cap=12 //slice=[1 2 1 2 3 4 3 4] 扩容 当新的len 等于cap时，继续追加元素将引发扩容机制，开辟新的底层数组，将原来的数据复制过去。旧的底层数组仍然会被旧slice引用，新slice和旧slice不再共享同一个底层数组。 扩容的容量将进行如下判断： 首先判断，如果新申请容量（cap）大于2倍的旧容量（old.cap），最终容量（newcap）就是新申请的容量（cap）。 否则判断，如果旧切片的长度小于1024，则最终容量(newcap)就是旧容量(old.cap)的两倍。 否则判断，如果旧切片长度大于等于1024，则最终容量（newcap）从旧容量（old.cap）开始循环增加原来的1/4，即旧容量的1.25倍、1.5倍、1.75倍……直到最终容量（newcap）大于等于新申请的容量(cap)。 如果最终容量计算值溢出，则最终容量就是新申请容量(cap)。 my_slice := []int{1, 2, 3, 4, 5} // 限定长度和容量，且让长度和容量相等 new_slice := my_slice[1:3:3] // len=2 cap=2 [2 3] // 扩容 app_slice := append(new_slice, 44) // len=3 cap=4 [2 3 44] 当限定了slice的长度和容量时，如果需要扩容，golang将生成新的底层数组，而不是对原来的数组进行扩展，因此此时的新元素不会改变原来底层数组的值。 这样就可以解决上面提到的问题，因为创建了新的底层数组，所以修改不同的slice，将不会互相影响。为了保证每次都是修改各自的底层数组，通常会切出仅一个长度、仅一个容量的新slice，这样只要对它进行任何一次扩容，就会生成一个新的底层数组，从而让每个slice的底层数组都独立。 copy () copy(dst, src) 可以将src slice拷贝到dst slice。src比dst长，就截断; src比dst短，则只拷贝src那部分。这里的长度指len而不是容量cap。 copy的返回值是拷贝成功的元素数量，所以也就是src slice或dst slice中最小的那个长度。 s1 := []int{3, 4, 5} s2 := make([]int, 2, 7) copy(s1, s2) //s2: len=2 cap=7 [3 4] slice做函数参数 前面说过，slice的数据结构类似于[3/5]0xc000094030，仍可以将slice看作一种指针。这个特性直接体现在函数参数传值上。 Go中函数的参数是按值传递的，所以调用函数时会复制一个参数的副本传递给函数。如果传递给函数的是slice，它将复制该slice副本给函数，这个副本仍然是[3/5]0xc42003df10，它仍然指向源slice的底层数组。 如果函数内部对slice进行了修改，有可能会直接影响函数外部的底层数组，从而影响其它slice。但并不总是如此，例如函数内部对slice进行扩容，扩容时生成了一个新的底层数组，函数后续的代码只对新的底层数组操作，这样就不会影响原始的底层数组。 package main import \"fmt\" func main() { s1 := make([]int, 3, 4) // [0 0 0] foo(s1) printSlice(s1) // len=3 cap=4 [10 10 10] } func foo(s []int) { for i, _ := range s { //修改slice的值，将改变底层数组 s[i] += 10 } s = append(s, 3) //扩容将创建新的底层数组 s = append(s, 4) // len=5 cap=8 [10 10 10 3 4] s[1] = 20 //此时不会改变底层数组 printSlice(s) // len=5 cap=8 [10 20 10 3 4] } func printSlice(x []int) { fmt.Printf(\"len=%d cap=%d slice=%v\\n\", len(x), cap(x), x) } Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-09 12:41:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/list.html":{"url":"golang/list.html","title":"常用库 container/list","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 container/list 包学习笔记 函数和功能 节点 链表 使用 创建链表 操作 遍历链表 数据结构实现 节点 链表 插入 移除 移动 container/list 包学习笔记 golang 的链表list的使用和具体实现。list对存储的元素并没有类型限制，比较方便。实现方式值得学习借鉴。 函数和功能 首先列出节点和链表的成员函数和功能。 节点 Next() ：前趋指针 Prev() ：后趋指针 链表 Init() ：初始化链表 Len() ：链表长度 Front() ：返回第一个节点的指针 Back() ：返回最后一个节点的指针 Remove(e) ：删除节点e，返回e的值 PushFront(value) ：将value加入链表头部，返回该节点 PushBack(value) ：将value加入链表尾部，返回该节点 InsertBefore(value, e) ：将value插入节点e之前，返回该节点 InsertAfter(value, e) ：将value插入节点e之后，返回该节点 MoveToFront(e) ：将节点e移动到链表头部 MoveToBack(e) ：将节点e移动到链表尾部 MoveBefore(e, mark) ：将节点e移动到节点mark前面 MoveAfter(e, mark) ：将节点e移动到节点mark后面 PushBackList(list) ：将另一个链表list连接到本链表尾部 PushFrontList(list) ：将另一个链表list连接到本链表头部 使用 创建链表 //使用提供的New()进行初始化 l := list.New() //使用var关键字 var l list.List 操作 l := list.New() l.PushBack(1) // 1 e := l.PushBack(2) // 1,2 l.PushFront(3) // 3,1,2 e = l.InsertBefore(4,e) // 3,1,4,2 e = l.InsertAfter(5,e) // 3,1,4,5,2 l.MoveToBack(e) // 3,1,4,2,5 l2 := list.New() l2.PushBack(7) l2.PushBack(8) l2.PushBack(9) //l2: 7,8,9 l.PushBackList(l2) //l: 3,1,4,2,5,7,8,9 l.PushFrontList(l2) //l: 7,8,9,3,1,4,2,5,7,8,9 遍历链表 for e := l.Front(); e != nil; e = e.Next() { // do something with e.Value } 数据结构实现 golang 的 list 使用双向环形链表实现。用一个root节点同时表示头节点和尾节点，第一个元素root.next，最后一个元素root.prev。root本身不存储数据。 节点 首先看节点的数据结构，list存放节点属于的链表，用来检验操作的节点是否属于该链表，避免非法传参。value存储值，可以为任何类型。 type Element struct { next, prev *Element // The list to which this element belongs. list *List // The value stored with this element. Value interface{} } 成员函数有Next()和Prev(): func (e *Element) Next() *Element { if p := e.next; e.list != nil && p != &e.list.root { return p } return nil } 链表 type List struct { root Element len int } 元素的操作依靠root节点。除了root节点外，len存储节点个数，不包括root。 初始化 func (l *List) Init() *List { l.root.next = &l.root l.root.prev = &l.root l.len = 0 return l } // New returns an initialized list. func New() *List { return new(List).Init() } Front()和Back()可以看出root节点同时作为头节点和尾节点 func (l *List) Front() *Element { if l.len == 0 { return nil } return l.root.next } func (l *List) Back() *Element { if l.len == 0 { return nil } return l.root.prev } 插入 对于插入操作，首先实现了节点到节点的插入，然后在其上封装了value到节点的插入，可用于之后的各种插入操作。 func (l *List) insert(e, at *Element) *Element { e.prev = at e.next = at.next e.prev.next = e e.next.prev = e e.list = l l.len++ return e } func (l *List) insertValue(v interface{}, at *Element) *Element { return l.insert(&Element{Value: v}, at) } 所以可以容易得到PushFront()和PushBack()的实现 func (l *List) PushFront(v interface{}) *Element { l.lazyInit() return l.insertValue(v, &l.root) } func (l *List) PushBack(v interface{}) *Element { l.lazyInit() return l.insertValue(v, l.root.prev) } 注意这里使用了懒加载，在第一次使用到的时候再进行初始化 func (l *List) lazyInit() { if l.root.next == nil { l.Init() } } InsertBefore()和InsertAfter()同理，要记得检验节点是否属于该链表 func (l *List) InsertBefore(v interface{}, mark *Element) *Element { if mark.list != l { return nil } return l.insertValue(v, mark.prev) } PushBackList()和PushFrontList()是合并链表的操作。同样依赖于基本的插入操作。对传入的链表进行遍历，插入到对应的位置。 func (l *List) PushBackList(other *List) { l.lazyInit() for i, e := other.Len(), other.Front(); i > 0; i, e = i-1, e.Next() { l.insertValue(e.Value, l.root.prev) } } func (l *List) PushFrontList(other *List) { l.lazyInit() for i, e := other.Len(), other.Back(); i > 0; i, e = i-1, e.Prev() { l.insertValue(e.Value, &l.root) } } 移除 移除操作的基本操作remove()，双链表的移除，把没用的指针设为nil func (l *List) remove(e *Element) *Element { e.prev.next = e.next e.next.prev = e.prev e.next = nil // avoid memory leaks e.prev = nil // avoid memory leaks e.list = nil l.len-- return e } 然后封装得到Remove()，同样应当检查要删除的节点是否属于该链表 func (l *List) Remove(e *Element) interface{} { if e.list == l { l.remove(e) } return e.Value } 移动 实现节点到节点的移动 func (l *List) move(e, at *Element) *Element { if e == at { return e } e.prev.next = e.next e.next.prev = e.prev e.prev = at e.next = at.next e.prev.next = e e.next.prev = e return e } 然后基于这个可以实现各种移动操作 func (l *List) MoveToFront(e *Element) { if e.list != l || l.root.next == e { return } l.move(e, &l.root) } func (l *List) MoveToBack(e *Element) { if e.list != l || l.root.prev == e { return } l.move(e, l.root.prev) } func (l *List) MoveBefore(e, mark *Element) { if e.list != l || e == mark || mark.list != l { return } l.move(e, mark.prev) } func (l *List) MoveAfter(e, mark *Element) { if e.list != l || e == mark || mark.list != l { return } l.move(e, mark) } Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-07 11:06:30 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/string.html":{"url":"golang/string.html","title":"go 字符串","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 Go 字符串 字符串 定义字符串 拼接字符串 类型转换 检查前缀或后缀 Go 字符串 字符串 Go的字符串是一个任意字节的常量序列。Go语言中字符串的字节使用UTF-8编码表示Unicode文本，因此Go语言字符串是变宽字符序列，每一个字符都用一个或者多个字符表示，这跟其他的（C++，Java，Python 3）的字符串类型有着本质上的不同，后者为定宽字符序列。Go语言这样做不仅减少了内存和硬盘空间占用，同时也不用像其它语言那样需要对使用 UTF-8 字符集的文本进行编码和解码。 其他语言的字符串中的单个字符可以被字节索引，而Go中只有在字符串只包含7位的ASCII字符时才可以被字节索引。这并不代表Go在字符串处理能力上不足，因为Go语言支持一个字符一个字符的迭代，而且标准库中存在大量的字符串操作函数，最后我们还可以将Go语言的字符串转化为Unicode码点切片（类型为 [ ]rune），切片是支持直接索引的。 注：每一个Unicode字符都有一个唯一的叫做“码点”的标识数字。在Go语言中，一个单一的码点在内存中以 rune 的形式表示，rune表示int32类型的别名 定义字符串 字符串字面量使用双引号 \"\" 或者反引号 ` 来创建。 双引号用来创建可解析的字符串，支持转义，但不能用来引用多行； 反引号用来创建原生的字符串字面量，可能由多行组成，但不支持转义，并且可以包含除了反引号外其他所有字符。 s1 := \"Bourbon \\nBlog \\n\" s2 := `Bourbon\\n blog\\n ` fmt.Print(s1) fmt.Print(s2) 上面代码输出为： bourbon Blog Bourbon\\n blog\\n 可见，反引号定义的字符串不但保留了换行，还保留了缩进。 双引号创建可解析的字符串应用最广泛，反引号用来创建原生的字符串则多用于书写多行消息，HTML以及正则表达式。 拼接字符串 虽然Go中的字符串是不可变的，但是字符串支持 + 操作和+=操作 s1 := \"Bourbon\" s2 := \"blog\" s1 += \" \" + s2 fmt.Println(s1) // Bourbon blog 但这种方式在处理大量字符串连接的场景下将非常低效。使用 bytes.Buffer 连接字符串是一个更高效的方式，它会一次性将所有的内容连接起来转化成字符串。 var b bytes.Buffer for i := 0; i 下面比较两种拼接操作的性能差距 t := time.Now() var b bytes.Buffer for i := 0; i 可见，10000次的字符串拼接会导致数量级上的性能差距。 类型转换 在大多数语言中，可轻易地将任意数据类型转型为字符串。但在go中强制将整形转为字符串，你不会得到期望的结果。 i := 123 fmt.Println(string(i)) // { fmt.Println(strconv.Itoa(i)) // 123 string()会返回整型所对应的ASCII字符，想要正确将整型转换为字符串，应当使用strconv.Itoa() 。反之，将字符串转换为整型可以使用strconv.Atoi()。 另外还可以使用fmt.Sprintf函数将几乎所有数据类型转换为字符串，但通常应保留在这样的实例上，如正在创建的字符串包含嵌入数据，而非在期望将单个整数转换为字符串时用。 i := 123 s := fmt.Sprintf(\"the number is %d.\", i) fmt.Println(s) //the number is 123. 检查前缀或后缀 在处理字符串时，想要知道一个字符串是以一个特定的字符串开始还是以一个特定的字符串结束是非常常见的情况。可以使用strings.HasPrefix和strings.HasSuffix，它们将返回一个布尔值。 fmt.Println(strings.HasPrefix(\"something\", \"some\")) //true fmt.Println(strings.HasSuffix(\"something\", \"thing\")) //true Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-09 09:01:13 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/mutex.html":{"url":"golang/mutex.html","title":"互斥锁 / 读写锁","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 互斥锁 Mutex 与 读写锁 RWMutex 互斥锁 Mutex 使用 状态 自旋 普通模式 / 饥饿模式 读写锁 RWMutex 原理 使用 互斥锁 Mutex 与 读写锁 RWMutex 互斥锁 在操作系统中，当多线程并发运行时，可能会访问或修改到共享的代码。比如下面这个例子，多个goroutine同时修改 n 的值： n := 0 add := func() { n = n + 1 } for i := 0; i 最终的输出很有可能不是100. 这是因为 n = n + 1在底层被解释为取值、加操作、赋值的3个操作。由于上下文切换，某个线程在执行这3个操作的过程中会被中断，另一个线程开始执行，从而导致了数据不一致。 这些共享资源的代码部分称为临界区（Critical Section）。应当保证临界区内代码的原子性。操作系统中使用信号量来保护临界区。对于上面这个例子，我们可以用二元信号量来保护临界区，即互斥锁。线程得到了资源，则对资源加锁，使用结束后释放锁。资源被加锁，其他线程将无法得到该资源，直到锁被释放。这样就保证了同时仅有1个线程正在访问资源。 Mutex 使用 Go 提供了 sync.Mutex来实现这个功能。Mutex只有两个方法：Lock() 和 Unlock()，分别代表了加锁和解锁。对于上面的例子，使用Mutex 来保护临界区： n := 0 mu := sync.Mutex{} add := func() { n = n + 1 } for i := 0; i 状态 查看源码，mutex的结构： type Mutex struct { state int32 sema uint32 } state 是状态码，包含了4项内容： Locked：表示是否上锁，上锁为1 未上锁为0 Woken：表示是否被唤醒，唤醒为1 未唤醒为0 Starving：表示是否为饥饿模式，饥饿模式为1 非饥饿模式为0 waiter：剩余的29位则为等待的goroutine数量 自旋 加锁时，如果当前Locked位为1，说明该锁当前由其他协程持有，尝试加锁的协程并不是马上转入阻塞，而是会持续的探测Locked位是否变为0，这个过程即为自旋过程。自旋时间很短（go设计为自旋4次），但如果在自旋过程中发现锁已被释放，那么协程可以立即获取锁。此时即便有协程被唤醒也无法获取锁，只能再次阻塞。 自旋的好处是，当加锁失败时不必立即转入阻塞，有一定机会获取到锁，这样可以避免协程的切换。 自旋的坏处是，如果自旋过程中获得锁，则马上执行该 goroutine。如果永远在自旋模式中，那么之前阻塞的goroutine 则很难获得锁，这样一来一些 goroutine 则会被阻塞时间过长。 普通模式 / 饥饿模式 go 对 mutex 的分配设计了两种模式。 在普通模式下，等待者以 FIFO 的顺序排队来获取锁，但被唤醒的等待者发现并没有获取到 mutex，并且还要与新到达的 goroutine 们竞争 mutex 的所有权。 在饥饿模式下，mutex 的所有权直接从对 mutex 执行解锁的 goroutine 传递给等待队列前面的等待者。新到达的 goroutine 们不要尝试去获取 mutex，即使它看起来是在解锁状态，也不要试图自旋。 读写锁 互斥锁的本质是当一个线程得到资源的时候，其他线程都不能访问。这样在资源同步，避免竞争的同时也降低了程序的并发性能。程序由原来的并行执行变成了串行执行。 其实，当我们对一个数据只做读操作的话，是不存在资源竞争的问题的。因为数据是不变的，不管多少个线程同时读取，都能得到同样的数据。所以问题不是出在读上，主要是写。要保证同时仅有一个线程在修改数据。所以真正的互斥应该是读和写、写和写之间，多个读者间没有互斥的必要。 因此，衍生出了读写锁。读写锁可以让多个读操作并发，但是对于写操作是完全互斥的。也就是说，当一个线程进行写操作的时候，其他线程既不能进行读操作，也不能进行写操作。 RWMutex 原理 操作系统中，可以使用信号量实现读写锁，也可以使用二元信号量即互斥锁实现。Go提供了读写锁sync.RWMutex，定义如下： type RWMutex struct { w Mutex // held if there are pending writers writerSem uint32 // 写锁需要等待读锁释放的信号量 readerSem uint32 // 读锁需要等待写锁释放的信号量 readerCount int32 // 读锁后面挂起了多少个写锁申请 readerWait int32 // 已释放了多少个读锁 } 可以看出RWMutex是基于Mutex实现的，在其基础上增加了读写的信号量。 读锁与读锁兼容，读锁与写锁互斥，写锁与写锁互斥，只有在锁释放后才可以继续申请互斥的锁： 可以同时申请多个读锁 有读锁时申请写锁将阻塞 只要有写锁，后续申请读锁和写锁都将阻塞 使用 提供了以下几个方法： //申请和释放写锁 func (rw *RWMutex) Lock() func (rw *RWMutex) Unlock() //申请和释放读锁 func (rw *RWMutex) RLock() func (rw *RWMutex) RUnlock() //返回一个实现Lock()和Unlock()的接口 func (rw *RWMutex) RLocker() Locker 如果不存在写锁，则Unlock()引发panic，如果不存在读锁，则RUnlock()引发panic 下面给出例子 package main import ( \"fmt\" \"sync\" \"time\" ) type data struct { N int RWM sync.RWMutex } func read(d *data, t time.Time) { d.RWM.RLock() time.Sleep(1 * time.Second) fmt.Printf(\"reader: n = %d, %s\\n\", d.N, time.Now().Sub(t).String()) d.RWM.RUnlock() } func write(d *data, t time.Time) { d.RWM.Lock() time.Sleep(3 * time.Second) d.N++ fmt.Printf(\"writer: n = %d, %s \\n\", d.N, time.Now().Sub(t).String()) d.RWM.Unlock() } func main() { t := time.Now() var d data for i := 0; i 创建了10个读线程，每个睡眠1秒；5个写线程，睡眠3秒。记录读者和写者的开始时间。输出如下： reader: n = 0, 1.000319542s reader: n = 0, 1.000435996s reader: n = 0, 1.000242171s reader: n = 0, 1.00048857s reader: n = 0, 1.000339988s reader: n = 0, 1.000224101s reader: n = 0, 1.000995623s writer: n = 1, 4.001359749s reader: n = 1, 5.001534292s reader: n = 1, 5.001578192s reader: n = 1, 5.001575223s writer: n = 2, 8.001839462s writer: n = 3, 11.00235864s writer: n = 4, 14.002692469s writer: n = 5, 17.002956352s 可以看出，由于可以同时读，多个读者间并没有发生阻塞。而写者由于锁机制，存在阻塞，延时3秒。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-13 13:48:52 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/channel.html":{"url":"golang/channel.html","title":"详解 go channel","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 详解 Go channel channel 简介 channel 创建 channel 的类型 有缓存的 channel 无缓存的 channel nil channel channel 关闭 range select 使用规则 循环监听 超时处理 源码 类定义 make 实现 send 实现 recive 实现 close 实现 详解 Go channel channel 简介 Channel是Go中的一个核心类型，是 goroutine 之间通信的一种方式，可以类比成 Unix 中的进程的通信方式管道。在CSP模型中，并发执行实体对应goroutine，消息通道对应channel。channel 本身还需关联了一个类型，也就是 channel 可以发送数据的类型。例如: 发送 int 类型消息的 channel 写作 chan int 。 channel 创建 channel使用内置函数 make() 创建，其中包括了数据类型，以及容量capacity 。容量代表channel容纳的最多的元素的数量，代表channel的缓存的大小。如果没有设置容量，或者容量设置为0, 则创建的是无缓存channel。 ch := make(chan int, 100) channel和 slice，map 类似，make 创建了一个底层数据结构的引用，当赋值或参数传递时，只是拷贝了一个 channel 引用，指向相同的 channel 对象。和其他引用类型一样，channel 的空值为 nil 。使用 == 可以对类型相同的 channel 进行比较，只有指向相同对象或同为 nil 时，才返回 true. channel 的类型 有缓存的 channel 创建时指定了channel的容量，则为有缓存的channel。 类似一个阻塞队列（环形数组实现），当缓存未满时，向 channel 中发送消息时不会阻塞; 当缓存满时，发送操作将被阻塞，直到有其他 goroutine 从中读取消息； 相应的，当 channel 中消息不为空时，读取消息不会出现阻塞；当 channel 为空时，读取操作会造成阻塞，直到有 goroutine 向 channel 中写入消息。 通过 len 函数可以获得 chan 中的元素个数，通过 cap 函数可以得到 channel 的缓存长度。 无缓存的 channel 创建时未指定channel的容量，则为无缓存的channel。 从无缓存的 channel 中读取消息会阻塞，直到有 goroutine 向该 channel 中发送消息； 向无缓存的 channel 中发送消息也会阻塞，直到有 goroutine 从 channel 中读取消息。 func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c 这个例子中，主线程x, y := 会一直被阻塞，直到有数据被发送到channel。从而实现了goroutine的同步。 nil channel 当未为channel分配内存时，channel就是nil channel。nil channel会永远阻塞对该channel的读、写操作。 var ch chan int // nil channel 因此，channel 一定要初始化后才能进行读写操作，否则会永久阻塞。 channel 关闭 golang 提供了内置的 close 函数对 channel 进行关闭操作。 ch := make(chan int) close(ch) 关闭一个nil channel 会产生 panic 重复关闭同一个 channel 会产生 panic 向一个已关闭的 channel 中发送消息会产生 panic 从已关闭的 channel 读取消息不会产生 panic，且能读出 channel 中还未被读取的消息。若消息均已读出，则会读到类型的零值。 从已关闭的 channel 中读取消息永远不会阻塞，并且会返回一个为 false 的 ok-idiom，可以用它来判断 channel 是否关闭 c := make(chan int, 10) close(c) i, ok := 关闭 channel 会产生一个广播机制，所有向 channel 读取消息的 goroutine 都会收到消息 range channel 也可以使用 range 遍历，并且会一直从 channel 中读取数据，直到有 goroutine 对改 channel 执行 close 操作，循环才会结束。如果没有goroutine 对channel 进行写操作，则会发生死锁。 func main() { ch := make(chan int, 10) ch 这个例子将输出 1 2 3，然后发生死锁，因为检测到不会再对channel进行写操作。 select 使用规则 select 可以同时监听多个 channel 的消息状态。类似于switch，但是只用于通信。 select { //do something case select 可以同时监听多个 channel 的写入或读取 执行 select 时，若只有一个 case 通过(不阻塞)，则执行这个 case 块 若有多个 case 通过，则随机挑选一个 case 执行 若所有 case 均阻塞，且定义了 default 模块，则执行 default 模块。若未定义 default 模块，则 select 语句阻塞，直到有 case 被唤醒。 nil channel上的操作会一直被阻塞，如果没有default case,只有nil channel的select会一直被阻塞。 使用 break 可以跳出 select 。 循环监听 select 和 switch 一样，它只会选择一个case来处理，如果想一直处理channel，可以在外面加一个无限的for循环，直到收到某信号后退出： for { select { case c 超时处理 因为上面我们提到，如果没有case需要处理，select语句就会一直阻塞着。这时候我们可能就需要一个超时操作，用来处理超时的情况。 func main() { c1 := make(chan string, 1) go func() { time.Sleep(time.Second * 2) c1 这个例子中，2秒后往 c1 中发送一个数据，但是 select 设置为1秒超时,因此我们会打印出timeout 1。它利用的是time.After方法，它返回一个类型为的单向的channel，在指定的时间发送一个当前时间给返回的channel中，被 select 接收，从而实现定时。 源码 $GOROOT/src/runtime/chan.go 类定义 type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } type waitq struct { first *sudog last *sudog } make 实现 func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size >= 1 maxAlign { throw(\"makechan: bad alignment\") } mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem > maxAlloc-hchanSize || size send 实现 // entry point for c 0 { t0 = cputicks() } lock(&c.lock) if c.closed != 0 { unlock(&c.lock) panic(plainError(\"send on closed channel\")) } if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(&c.lock) }, 3) return true } if c.qcount 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) return true } recive 实现 // entry points for 0 { t0 = cputicks() } lock(&c.lock) if c.closed != 0 && c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(&c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender's value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() { unlock(&c.lock) }, 3) return true, true } if c.qcount > 0 { // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled { raceacquire(qp) racerelease(qp) } if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(&c.lock) return true, true } if !block { unlock(&c.lock) return false, false } // no sender available: block on this channel. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) gopark(chanparkcommit, unsafe.Pointer(&c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // someone woke us up if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime > 0 { blockevent(mysg.releasetime-t0, 2) } closed := gp.param == nil gp.param = nil mysg.c = nil releaseSudog(mysg) return true, !closed } close 实现 func closechan(c *hchan) { if c == nil { panic(plainError(\"close of nil channel\")) } lock(&c.lock) if c.closed != 0 { unlock(&c.lock) panic(plainError(\"close of closed channel\")) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } c.closed = 1 var glist gList // release all readers for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // release all writers (they will panic) for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(&c.lock) // Ready all Gs now that we've dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-09 12:41:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/json.html":{"url":"golang/json.html","title":"go 读写json文件","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 golang 读写 json 文件 将 struct 写入 json 文件 将 struct 转换成 json 将 json 写入文件 读取 json 文件转换 struct 读取json 文件 解析到结构体 golang 读写 json 文件 将 struct 写入 json 文件 定义一个结构体，注意成员名大写，否则 json 无法读取。 type Student struct { ID int Name string Scores []int } 将 struct 转换成 json tom := Student{ ID: 1, Name: \"Tom\", Scores: []int{99, 100, 80, 77}, } json, err := json.Marshal(tom) if err != nil { log.Fatal(err) } 将 json 写入文件 创建 test.json 文件，然后写入。 err = ioutil.WriteFile(\"test.json\", json, os.ModeAppend) if err != nil { log.Fatal(err) } test.json: {\"ID\":1,\"Name\":\"Tom\",\"Scores\":[99,100,80,77]} 读取 json 文件转换 struct 读取json 文件 stu := Student{} j, err := ioutil.ReadFile(\"test.json\") if err != nil { log.Fatal(err) } 解析到结构体 err = json.Unmarshal(j, &stu) if err != nil { log.Fatal(err) } fmt.Print(stu) // {1 Tom [99 100 80 77]} Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-10 12:28:07 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/https.html":{"url":"network/https.html","title":"HTTP 和 HTTPS","keywords":"","body":"HTTP 和 HTTPS Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-17 07:54:27 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"linux/chmod.html":{"url":"linux/chmod.html","title":".sh 添加执行权限","keywords":"","body":"给 .sh 文件添加执行权限 chmod u+x file.sh chmod (change the permissions mode of a file) 权限管理命令。 u代表所有者，x代表执行权限。 + 表示增加权限。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-08 05:47:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/git.html":{"url":"other/git.html","title":"Git同步本地项目到Github","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 Git同步本地项目到Github 本地git获取github提交权限 设置用户名和邮箱 生成ssh密钥 复制到github 测试完成 创建本地仓库 创建远程仓库 将本地仓库同步到远程仓库 添加远程仓库 将本地仓库的内容push到远程仓库的master分支 Git同步本地项目到Github 将本地的项目同步到github上，这样可以随时pull到本地，修改完后再push到github仓库。可以随时随地修改代码，也避免了项目的丢失的风险。 本地git获取github提交权限 设置用户名和邮箱 git config --global user.name 'your_name' git config --global user.email 'your_email' 生成ssh密钥 ssh-keygen -t rsa -C 'your_email' 提示设置存储位置和口令等，回车跳过。默认存储在 ~/.ssh/id_rsa.pub 复制到github 将生成的id_rsa.pub文件中的公钥复制到github的setting / SSH AND GPG KEY / SSH keys 测试完成 ssh git@github.com 提示 successfully authenticated 则成功。 创建本地仓库 cd到项目目录 git init 初始化git仓库 git add . 把所有项目文件添加到提交暂存区 git commit -m '提交说明' 把暂存区中的内容提交到仓库 创建远程仓库 github新建仓库，假设仓库名为[resName] 将本地仓库同步到远程仓库 添加远程仓库 git remote add origin git@github.com:[githubUerName]/[resName] 将本地仓库的内容push到远程仓库的master分支 git push -u origin master push的-u参数是设置本地仓库默认的upstream,这里就是把本地仓库同远程仓库的master分支进行关联，之后你在这个仓库pull时不带参数也默认从master分支拉取. Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-07 11:06:30 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/gitbook.html":{"url":"other/gitbook.html","title":"使用 Gitbook 搭建博客","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 使用 Gitbook 搭建博客 安装 node.js 编辑工具 Gitbook 初始化 目录 启动服务 插件 webhook 实现服务器自动更新博客 docker 部署 webhook 启动 webhook 配置 github 使用 Gitbook 搭建博客 gitbook 使用markdown 编写，简单易用。通过配置插件，也可以添加很多主题和小功能。适合搭建博客，电子书等。 安装 node.js gitbook是一个基于Node.js的命令行工具，所以要先安装Node.js(下载地址https://nodejs.org/en/，找到对应平台的版本安装即可)。 或使用包管理安装。 apt-get install nodejs 安装Gitbook： npm install -g gitbook-cli 编辑工具 typora：https://www.typora.io/ apt-get install typora Gitbook 初始化 在空文件夹中执行 gitbook init 文件夹中将多两个文件 README.md ：封面介绍 SUMMARY.md ：配置目录结构 目录 编辑SUMMARY.md # Summary * [Introduction](README.md) * [前言](readme.md) * [第一章](part1/README.md) * [第一节](part1/1.md) * [第二节](part1/2.md) * [第三节](part1/3.md) * [第四节](part1/4.md) * [第二章](part2/README.md) * [第三章](part3/README.md) * [第四章](part4/README.md) 编辑后执行 gitbook init 将自动按以上目录寻找或创建文件。 每一篇文章都是一个.md文件，这样就可以开始写博客了。 启动服务 编辑好文件后，执行 gitbook init gitbook serve gitbook将在本地4000端口启动服务。浏览器访问 http://localhost:4000/ 至此，已经可以使用 gitbook 搭建博客了。 插件 文件夹下创建 book.json ，如果已有，就直接打开。 配置插件等都是在这里，也可以复制别人的配置项。 plugins 是配置插件的位置，gitbook自带了5个插件，在名字前面加 - 可以禁用插件： sharing：右上角分享功能 font-settings：字体设置（左上方的\"A\"符号） livereload：为 GitBook 实时重新加载 highlight： 代码高亮 search： 导航栏查询功能（不支持中文） 推荐几个我在使用的插件： page-treeview：每篇文档头部生成标题树 code：为代码块添加行号和复制按钮 pageview-count：阅读量计数 popup：插件用于点击图片时，打开新的网页用来查看高清大图。 tbfed-pagefooter：在每个页面的最下方自动添加页脚信息 favicon：修改网页标题的图标 search-plus：原搜索插件不支持中文搜索，所以使用该插件进行替换。 expandable-chapters 和 chapter-fold ：导航目录 hide-element：隐藏界面元素 back-to-top-button：返回顶部按钮 splitter：侧边栏可自行调整宽度 sharing-plus：分享当前页面，比默认的 sharing 插件多了一些分享方式。 donate：打赏模块，在每篇文章底部都会加上一个按钮，点击显示图片 github：右上角跳转到 github 主页 附上我的配置文件 { \"author\": \"Bourbon\", \"description\": \"学习，记录，分享，进步\", \"extension\": null, \"generator\": \"site\", \"isbn\": \"\", \"links\": { \"sharing\": { \"all\": null, \"facebook\": null, \"google\": null, \"twitter\": null, \"weibo\": null } }, \"output\": null, \"pdf\": { \"fontSize\": 12, \"footerTemplate\": null, \"headerTemplate\": null, \"margin\": { \"bottom\": 36, \"left\": 62, \"right\": 62, \"top\": 36 }, \"pageNumbers\": true, \"paperSize\": \"a4\" }, \"plugins\": [ \"page-treeview\", \"code\", \"pageview-count\", \"popup\", \"tbfed-pagefooter\", \"favicon\", \"search-plus\", \"expandable-chapters\", \"hide-element\", \"back-to-top-button\", \"splitter\", \"-lunr\", \"-search\", \"-sharing\", \"sharing-plus\", \"chapter-fold\", \"donate\", \"github\" ], \"pluginsConfig\": { \"code\": { \"copyButtons\": false }, \"hide-element\": { \"elements\": [\".gitbook-link\"] }, \"tbfed-pagefooter\": { \"copyright\": \"Copyright © 1141134779@qq.com 2020\" }, \"favicon\": { \"shortcut\": \"assert/favicon.ico\", \"bookmark\": \"assert/favicon.ico\", \"appleTouch\": \"assert/favicon.ico\", \"appleTouchMore\": { \"120x120\": \"assert/favicon.ico\", \"180x180\": \"assert/favicon.ico\" } }, \"fontsettings\": { \"theme\": \"white\", \"family\": \"sans\", \"size\": 2 }, \"page-treeview\": { \"copyright\": \"Copyright © 1141134779@qq,com 2020\", \"minHeaderCount\": \"2\", \"minHeaderDeep\": \"2\" }, \"sharing\": { \"all\": [\"facebook\", \"google\", \"linkedin\", \"twitter\", \"weibo\", \"qq\"] }, \"donate\": { \"wechat\": \"/assert/wechat.jpg\", \"alipay\": \"/assert/alipay.jpg\", \"title\": \"\", \"button\": \"赏\", \"alipayText\": \"支付宝打赏\", \"wechatText\": \"微信打赏\" }, \"github\": { \"url\": \"https://github.com/BourbonWang\" } }, \"language\": \"zh-hans\", \"title\": \"Bourbon\", \"variables\": {}, \"styles\": { \"website\": \"/assert/styles/website.css\" } } webhook 实现服务器自动更新博客 由于需要频繁更新博客，不可能每次更新都重新上传服务器，所以需要服务器自动拉取gitbook文件夹。可以将gitbook上传到github，然后使用 webhook 将push与服务器关联。这样每次更新后push到github，然后webhook执行服务器的脚本，将文件夹 pull 下来，重启gitbook 服务。 docker 这里将博客放到docker里，方便管理，不会与其他服务冲突。 拉取 node 镜像，创建容器 docker run -itd --name blog -p 4000:4000 node:10.19 /bin/bash docker exec -it blog /bin/bash 容器内同样方法安装gitbook。 部署 webhook apt 换源(debian)后，安装 pip apt-get install python3-pip 我使用的 webhookit：https://github.com/hustcc/webhookit 可根据文档自行安装。 由于这个webhook只能用python2, 注意使用 pip2。 pip2 install webhookit webhookit_config > /home/webhook/config.py 编辑config.py ，只需要修改repo_name/branch_name 和 SCRIPT # -*- coding: utf-8 -*- ''' Created on Mar-03-17 15:14:34 @author: hustcc/webhookit ''' # This means: # When get a webhook request from `repo_name` on branch `branch_name`, # will exec SCRIPT on servers config in the array. WEBHOOKIT_CONFIGURE = { # a web hook request can trigger multiple servers. 'repo_name/branch_name': [{ # if exec shell on local server, keep empty. 'HOST': '', # will exec shell on which server. 'PORT': '', # ssh port, default is 22. 'USER': '', # linux user name 'PWD': '', # user password or private key. # The webhook shell script path. 'SCRIPT': '/home/webhook/shell.sh' }, ...], ... } 创建shell.sh，就是自动执行的脚本，用来拉取博客，完成更新 cd /home/blog git pull gitbook install gitbook init gitbook serve 启动 webhook webhookit -c /home/webhook/config.py -p 4001 监听4001端口，浏览器访问即可查看webhook URL以及配置信息。 配置 github 仓库 -> Settings -> Webhooks -> Add webhook payload URL：填写webhook URL Content type ：application/json 触发条件：Just the push event. Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-07 14:28:32 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/http.html":{"url":"network/http.html","title":"HTTP 和 HTTPS","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 HTTP 与 HTTPS HTTP 特点 基于请求和响应 无状态 无连接 简单快速、灵活 请求报文 请求行 请求头 请求体 响应报文 状态行 响应头 存在的问题 HTTPS 加密 数字摘要 数字签名 过程 不足 安全性 成本 HTTP 与 HTTPS HTTP HTTP是超文本传输协议的缩写，是一个基于请求与响应，无状态的，应用层的协议，常基于TCP/IP协议传输数据，互联网上应用最为广泛的一种网络协议，所有的WWW文件都必须遵守这个标准。设计HTTP的初衷是为了提供一种发布和接收HTML页面的方法。随着发展，HTTP可以支持传输任何类型的数据。 特点 基于请求和响应 HTTP协议一般用于B/S架构，浏览器向服务端发送请求报文，服务器解析后，将数据包含在响应报文中，发送给浏览器。 无状态 协议对事务处理没有记忆能力，后续处理如果需要之前的信息，则必须重传。比如访问一个网站需要反复进行登录操作。对于这个特点，现有的一些解决方案比如 利用 Cookie / Session HTTP/1.1持久连接（HTTP keep-alive）。只要任意一端没有明确提出断开连接，则保持TCP连接状态，在请求首部字段中的Connection: keep-alive即为表明使用了持久连接 这样可以让用户在登陆后一段时间内不需要再次登陆。 无连接 由于无状态特点，每次请求需要通过TCP三次握手四次挥手，和服务器重新建立连接。当一个用户与服务器进行频繁的请求时，建立TCP连接将耗费大量的开销。 为此，HTTP/1.1 支持了长连接，与同一个用户的多次数据传输可以使用同一个TCP信道。但对一个信道的多个请求存在排队，不支持同时处理多个HTTP连接。 HTTP/2.0在其上实现了多路复用，对于同时的多个请求，可以同时在信道上发送和接收，大幅缩短资源请求的耗时，在请求大数量资源时效果显著。 简单快速、灵活 客户向服务器请求服务时，只需传送请求方法和路径。HTTP允许传输任意类型的数据对象。传输的类型由Content-Type加以标记。 请求报文 一个HTTP请求报文由请求行（request line）、请求头（header）、空行和请求体4个部分组成。 请求行 请求行由三部分组成：请求方法，请求URL（不包括域名），HTTP协议版本。 请求方法有 GET：获得URI指定的资源，参数放在URL后面。传输过程中可能会被浏览器、网关等缓存，参数可以直接在地址栏看到，不适合用来传递敏感数据。一些浏览器或服务端对URL的长度有限制，不适合传递大量数据。浏览器中点击的URL都是GET请求。 POST: 请求参数放在请求体中，以key1=value1&key2=value2的形式存放，不会显示在URL中。POST请求不会被缓存，可以用来传递用户信息等敏感数据。请求体没有长度限制，所以可以传递大量数据。浏览器的表单提交、文件上传等都是POST。 HEAD：和GET相似，不过服务端接收到HEAD请求时只返回响应头，不发送响应体。使用HEAD不必传输整个资源内容，就可以得到资源的信息。所以，如果只需要查看某个页面的状态时，用HEAD更高效，因为省去了传输页面内容的时间。 PUT: 向服务器发送请求存储一个资源，并用URI作为标识。PUT和POST都是向服务器发送数据，但PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定。 DELETE: 请求服务器删除URI指定的资源 OPTIONS: 用于获取当前URL所支持的方法。若请求成功，会在HTTP头中包含一个名为“Allow”的头，值是所支持的方法，如“GET, POST”。 TRACE: 请求服务器回送收到的请求信息，主要用于测试。 CONNECT: HTTP/1.1的方法，将连接转换为一个TCP/IP管道，通常用于SSL加密服务器的链接与非加密的HTTP代理服务器的通信。 请求头 User-Agent : 产生请求的浏览器类型 Accept : 希望接受的数据类型，比如 Accept：text/xml（application/json） Accept-Encoding: 浏览器表明自己接收的编码方法 Accept-Language: 浏览器接收的语言 Accept-Charset: 接收的字符集 Content-Length：请求体的长度 Content-Type：请求体的数据类型。比如 Content-Type：text/html（application/json） Referer：提供了该请求从哪个链接跳转而来 Connection：标明Connection: keep-alive则为长连接。请求结束后，建立的TCP连接不会关闭，当客户端再次请求相同的服务器时，将继续使用这个TCP连接。有保持时间限制。 Host: 请求的主机名，从URL中提取。 If-Modified-Since: 检查资源的修改时间，和响应头的Last-Modified一起。当请求同一个资源时，将上一次请求返回的Last-Modified填入If-Modified-Since中。服务器将这个时间与真实资源的修改时间对比。如果未过期，则返回304, 使用缓存的文件。如果过期，则返回200, 将新的资源返回给浏览器。 Cache-Control: 指定缓存机制。Public表示可以被任何缓存；Private表示只缓存到私有缓存中；no-cache表示不会被缓存。 Cookie：将cookie的值发给服务器。可以用来发送session id等。 请求体 在浏览器发送HTTP请求时，GET请求往往通过URL来发送，这时无法设置请求体，只有URL，请求数据只能放在URL的querystring中；POST请求往往来自表单提交或发送文件，POST仍然可以在URL上附带一些参数，只不过表单里的数据都放在请求体中。 实际使用HTTP作为接口时，无论GET还是POST都可以使用请求体。我们通常把所有的“控制类”信息应该放在请求头中，具体的数据放在请求体里。于是服务器端在解析时，总是会先完全解析全部的请求头部。这样服务器端总是希望能够了解请求的控制信息后，就能决定这个请求进一步如何处理，是拒绝，还是处理数据，或者直接转发。比如，收到一个请求，检查请求头看到Content-Length里的数太大，或者Content-Type自己不支持，或者Accept要求的格式无法处理，就可以直接返回失败，节省了读取请求体的带宽。 响应报文 响应报文与请求报文的结构相似，也是由状态行，响应头，空行，响应体组成。 状态行 状态行包含了HTTP版本，状态码，以及状态码的描述。 状态码由3位十进制数字组成。详细请看HTTP状态码 1xx（信息）：收到请求，需要继续执行操作 101：Continue, 客户端继续请求 2xx（成功）：请求已成功接收并处理 200：OK，请求成功 201：Created，已创建 202：Accepted, 已接受 3xx（重定向）：需要采取进一步措施才能完成请求 301：Moved Permanently，永久重定向。浏览器会记录新的URI，以后直接跳转到新的URI。 302：Found，临时重定向。以后浏览器仍然使用原有URI访问服务器，可用来流量统计等。 304：Not Modified，未修改。客户端通过If-Modified-Since检查资源时，如果资源未修改，服务器返回此状态码，不会返回任何资源，客户端使用本地的缓存。 4xx（客户端错误）：请求包含错误的语法或无法完成请求 400：Bad Request，客户端请求的语法错误，服务器无法理解 401：Unauthorized，要求用户身份验证 403：Forbidden，服务器理解请求，但是拒绝执行此请求 404：Not-Found，服务器无法根据客户端的请求找到资源。通过此代码，网站设计人员可设置\"您所请求的资源无法找到\"的个性页面 405：Method Not Allowed，客户端请求中的方法被禁止 5xx（服务器错误）：服务器在处理请求时发生错误 500：Internal Server Error，服务器内部错误，无法完成请求 501：Not Implemented，服务器不支持请求的功能，无法完成请求 502：Bad Gateway，作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 503：Service Unavailable，由于超载或系统维护，服务器暂时的无法处理客户端的请求。 504：Gateway Time-out，充当网关或代理的服务器，未及时从远端服务器获取请求 505：HTTP Version not supported，服务器不支持请求的HTTP协议的版本，无法完成处理 响应头 Content-Type: 响应体的数据类型 Content-Length: 响应体的长度 Content-Encoding: 响应体的编码和压缩方式 Content-Language: 响应体语言 Last-Modified: 指定资源的最后修改时间 Server: 服务器的软件信息 Connection: 和请求头的Connection相同 Location: 重定向的新地址 Date: 生成报文的具体时间 Expires: 告诉浏览器在指定过期时间内使用本地缓存 Set-Cookie: 发送cookie，用来把新创建的session id返回给客户端 存在的问题 请求信息明文传输，容易被窃听截取。 数据的完整性未校验，容易被篡改。 没有验证对方身份，存在冒充危险。 HTTPS 为了解决上述HTTP存在的问题，就用到了HTTPS。HTTPS是一种通过计算机网络进行安全通信的传输协议，经由HTTP进行通信，利用SSL/TLS建立全信道，加密数据包。HTTPS使用的主要目的是提供对网站服务器的身份认证，同时保护交换数据的隐私与完整性。 加密 发送方随机生成密钥对消息进行对称加密。使用接收方的公钥加密对称密钥，仅有接收方可以解密，从而得到对称密钥解出明文。任何中间人无法得到接收方的私钥，也就无法破解消息。 数字摘要 对消息进行哈希，得到固定长度的唯一的码，不同消息的哈希码不同，将此哈希码一同发送给接收方，用于消息验证。接收方用同样的哈希函数对收到的明文进行哈希，与收到的哈希码比较，从而可以判断消息是否完整或被更改。由于哈希函数本身保证了无法从哈希码反推出明文，因此可以保证数字摘要是可靠的。 数字签名 验证消息是否真实来自发送方，也可以认为是验证数字摘要是否真实来自发送方。发送方用发送方的私钥对数字摘要进行加密。这样仅能用发送方的公钥进行解密，中间人无法进行伪造。 过程 首先客户端通过URL访问服务端443端口请求建立SSL连接。包括加密协议，版本，随机数1等等 服务端选择合适的加密协议，产生随机数2, 返回客户端 服务端随即发送CA证书，其中包含了服务端的公钥。 客户端验证证书。生成一个随机数，即预主密钥。 客户端通过随机数1,随机数2,预主密钥组合成会话密钥。用服务端的公钥进行加密 服务端收到后用私钥解密，同样的方式组装出会话密钥。 服务端用会话密钥加密一条消息发送回客户端，用来验证是否得到了正确的会话密钥。 客户端同样用会话密钥加密一条消息，用来告诉服务端消息可以正常接收。 SSL连接建立完成。 不足 安全性 HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用 SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行 成本 SSL证书需要购买，功能越强大的证书费用越高 HTTPS协议多次握手，会使页面的加载时间延长近50%，增加耗电。比较好的方式是采用分而治之，网站主页使用HTTP协议，有关于用户信息等方面使用HTTPS。 HTTPS连接缓存不如HTTP高效，流量成本高。 SSL涉及到的安全算法会消耗 CPU 资源，对服务器资源消耗较大。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-17 08:41:04 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/tcp.html":{"url":"network/tcp.html","title":"TCP详解","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 TCP 详解 特点 报文 可靠数据传输 确认应答机制 滑动窗口 超时重传 快速重传 建立和结束连接 流量控制 延迟应答 拥塞控制 加性增，乘性减（AIMD） 慢启动 TCP 详解 TCP是运输层的可靠运输协议。HTTP，HTTPS，SSH，Telnet，FTP等应用层协议都是基于TCP。 特点 TCP是面向连接的。因为在一个进程可以开始向另一个进程发送数据之前，这两个进程必须先握手，即必须相互发送一些特殊的报文，以确定数据传输所需的参数。 TCP提供全双工服务。如果进程A与进程B存在TCP连接，那么应用层数据就可以在两个进程间双向流通。 TCP连接是点对点的。即单个发送方与单个接收方间的连接。TCP用（源IP地址，源端口号，目的IP地址，目的端口号）四元组来唯一标识进程。 TCP是面向字节流的。对于每个连接，TCP会建立发送缓冲区和接收缓冲区。上层应用会将数据放入缓冲区，TCP会按MSS（最大报文段长）分割成一个个报文，在合适时机发送出去。接收数据的时候，应用也是从缓冲区读取数据。因此TCP的读与写不需要完全匹配。 TCP通过报文段检验和，确认应答，超时重传，流量控制，拥塞控制等机制提供可靠传输。 报文 32位序号: 序号是该报文段首字节的编号。 32位确认号：TCP是全双工的，在发送数据的同时也在接收对方的数据。主机A填充进报文段的确认号是主机A期望从B收到的下一字节的序号。序号和确认号是保证TCP可靠传输的关键。 4位首部长度：从首部到数据部分的偏移量，一般TCP首部长度为20字节 6位标志位 URG: 标识紧急指针是否有效 ACK: 标识确认序号是否有效 PSH: 用来提示接收端应用程序立刻将数据从tcp缓冲区读走 RST: 要求重新建立连接. 我们把含有RST标识的报文称为复位报文段 SYN: 请求建立连接. 我们把含有SYN标识的报文称为同步报文段 FIN: 通知对端, 本端即将关闭. 我们把含有FIN标识的报文称为结束报文段 16位窗口：用于流量控制，指示接收方愿意接收的字节数量 16位检验和：校验和不光包含TCP首部, 也包含TCP数据部分 可靠数据传输 确认应答机制 TCP使用序号和确认号实现可靠传输。当A向B发送数据时，携带序号Seq Num为该报文段的首字节的编号；确认号Ack Num为期望对方下次发送报文的首字节编号，同时也告诉对方Ack Num之前的数据都已接收。从直观上，发送的每个报文都应当得到一个专门的ACK回应。实际上，双方往往是在互相发送各自的数据，然后各自回应对方。因此可以在发送自己的数据的时候，顺便带上回应对方的ACK。 滑动窗口 窗口大小指的是无需等待确认应答就可以继续发送数据的最大值. 发送方将维护一个滑动窗口。窗口内的报文不需要等待ACK应答，直接发送。 对于接收方：如果一个序号n的分组被正确的接收，且按序（即上次交付给上层的是序号n-1的分组），则为序号n的分组回应ACK，然后交付给上层。对于正确但无序的分组，TCP对将其暂时缓存，应答ACK仍为最近按序正确接收的分组序号。 因此，如果发送方收到分组k的应答ACK，说明k和k之前的分组都已成功接收。发送方可以将被确认过的数据从缓冲区删掉，窗口向前移动，继续发送其他的报文。 超时重传 发送的数据报文或应答的ACK报文可能在网络中丢失。当发送报文一段时间后仍未收到确认ACK，TCP将重新发送该报文，然后重置定时器。 对于连续发送的报文，如果第一个报文触发了超时重传，而在新的超时时间之前收到了第二个报文ACK，第二个报文将不会重传。 快速重传 超时重传的问题是超时周期可能较长。当一个分组丢失时，发送方可能要等待很久才重传分组，从而增加端到端的时延。事实上，发送方往往一次发送大量的分组，当有分组丢失时，会引起大量相同的冗余ACK。如果TCP发送方收到了超过3个冗余的ACK，它就认为这之后的分组发生丢失，TCP将进行快速重传。 建立和结束连接 TCP采用三次握手来创建连接，四次挥手来断开连接。详细请见另一篇文章: TCP三次握手和四次挥手 流量控制 前面说到，双方都为该连接设置了接收缓存。当接收到正确的报文后，它就将数据放入缓存。上层的应用进程会从缓存中读取数据，但没必要数据刚到达就读取，应用进程甚至可能过很长时间后才读取。如果数据读取十分缓慢，而发送方发送的数据太多太快，会导致接收缓存溢出。 为此，TCP提供了流量控制。流量控制是保证了发送速率和接收方的读速率相匹配。接收方将剩余缓存大小填入TCP报头的“窗口”字段，用于告诉发送方，自己还有多少缓存空间。窗口越大，说明接收方的吞吐量越高。由于TCP是全双工的，双方都各自维护一个接收窗口。 当接收方的缓冲区快满了，会将更小的窗口通知发送方，发送方会减慢自己的发送速度。当窗口为0时，发送方不再发送数据，但会定期的发送只有一个字节的报文段，用于探测接收方的窗口。 延迟应答 如果接收数据后立即进行ACK应答，这时返回的窗口可能比较小。实际上，接收方的处理数据速度可能很快，稍等一段时间就可以得到更大的缓冲区，返回更大的窗口。窗口越大, 网络吞吐量就越大, 传输效率就越高。TCP的目标是在保证网络不拥堵的情况下尽量提高传输效率。但延迟应答也有限制： 数量限制: 每隔N个包就应答一次 时间限制: 超过最大延迟时间就应答一次 拥塞控制 数据的丢失一般是在网络拥塞时由于路由器缓存溢出引起的。因此，分组重传是网络拥塞的征兆，但不能解决网络拥塞问题。TCP需要另一些机制在面临网络拥塞时遏制发送方。TCP拥塞控制的基本思想是，当出现丢包事件（收到3个冗余ACK）时，让发送方通过减小拥塞窗口的大小来降低发送速率。TCP的拥塞控制算法包括：1. 加性增，乘性减（AIMD）; 2. 慢启动 加性增，乘性减（AIMD） 每发生一次丢包事件，发送方就将当前的窗口大小减半。但不能降到低于一个MSS（最大报文段长）。 当收到前面数据的ACK时，就可以认为当前网络没有拥塞，可以考虑增加发送速率。这种情况下，TCP每次收到一个ACK确认后就把窗口增加，每个往返时延内拥塞窗口增加1个MSS。 总而言之，TCP感受到网络无拥塞就加性的增加发送速率，感受到网络拥塞时就乘性的减小发送速率。因而称为加性增，乘性减（Additive-Increase，Multiplicative-Decrease）算法。 慢启动 在TCP连接刚开始时，初始的拥塞窗口被设为1个MSS，而实际可用的带宽往往比这大很多。仅仅线性的增加发送速率，可能要很长时间才能达到最大的速率。因此，TCP发送方在初始阶段并不是线性的增加发送速率，而是指数级的。直到发生第一个丢包事件（或到达阈值），窗口大小减为一半，然后才会加性增。这个指数级的增加发送速率的过程称为慢启动。 每当一个报文被确认后，窗口都增加1个MSS，从而使发送速率指数增长。比如：初始时只有1个MSS，发送一个报文。收到确认后，窗口增加1个MSS，然后就可以发出两个报文。这两个报文被确认后，窗口扩大到了4个MSS。因此在慢启动阶段，每过一个RTT，窗口都增加一倍。 为了方便窗口减半和控制慢启动的窗口上限，发送方记录了窗口的阈值。初始时设定为一个较大的值。慢启动阶段达到阈值后将开始加性增。然后每次增加窗口时，阈值都会随之增加。当出现丢包或超时事件时，阈值减半，即新的窗口大小。 事实上，TCP对超时事件的反应与丢包事件（收到3个冗余ACK）有所不同。当出现超时事件，TCP将阈值减半，然后将窗口直接减为1个MSS，然后重新开始慢启动阶段，直到达到减半后的阈值。TCP对丢包事件与超时事件采取不同策略是因为，当收到3个冗余ACK，仅代表一些报文丢失，而其他一些报文能够收到，TCP会尽可能的试探网络上能利用的带宽。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-22 10:10:10 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/three-way-handshake.html":{"url":"network/three-way-handshake.html","title":"TCP三次握手和四次挥手","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 TCP三次握手和四次挥手 三次握手 过程 第一次握手 第二次握手 第三次握手 原因 四次挥手 第一次挥手 第二次挥手 第四次挥手 常见问题 TCP三次握手和四次挥手 三次握手 过程 第一次握手 建立连接时，客户端发送SYN报文，标志位SYN=1。 随机生成初始序列号ISN，作为序列号Seq Num = client_isn。ISN动态随机生成使得每个tcp session的字节序列号没有重叠。也为了增加安全性，为了避免被第三方猜测，从而被第三方伪造的RST报文Reset。伪造的报文要想成功，需要Seq Num 位于对方的合法接收窗口内， 而由于ISN是动态随机的，猜出对方接收窗口难度加大。 规定第一次握手不携带数据。如果第一次握手携带数据，先由服务端缓存下来等建立连接后再处理，这样会导致SYN FLOOD攻击。攻击者会用大量的携带数据的握手报文，让接收方被迫开辟大量的空间来缓存这些数据，从而耗尽内存，关闭服务。 客户端进入SYN_SENT状态，等待服务器确认。 第二次握手 服务器收到SYN报文后，如果同意连接，则发出确认报文。告知客户端：客户端发送正常，服务端接收正常。 确认报文中的标志位 ACK=1, SYN=1, 确认序号Ack Num = client_isn + 1, 同时也要为自己初始化一个序列号 Seq Num= server_isn。这个报文也不能携带数据, 但是同样要消耗一个序号。 TCP服务器进程进入了SYN-RCVD状态。 第三次握手 客户端收到确认报文后，再次向服务器确认，告知服务器：客户端接收正常，服务器发送正常。 确认报文的标志位ACK=1，序列号Seq Num = client_isn + 1, 确认序号Ack Num = server_isn + 1， 第三次握手时可以携带数据。因为伪造的第三方是无法接收到第二次握手的报文，能发出第三次握手报文的用户都是合法的。 TCP连接建立，客户端进入ESTABLISHED状态。当服务器收到客户端的确认后也进入ESTABLISHED状态，就可以正常处理携带的数据。此后双方就可以开始通信了。 原因 从建立连接的过程可以知道，三次握手是可以让双方确认彼此收发能力的最小次数。除此之外，三次握手还有其他原因： 阻止重复历史连接的初始化 The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion. RFC 793指出，三次握手的主要原因是防止旧的重复连接初始化造成混乱。 比如客户端发送一个Seq Num = 50的SYN报文1，由于网络阻塞，客户端又重新发送发送了一个Seq Num = 100的SYN报文2。一段时间后，服务器先收到了SYN报文1，并且返回Ack Num = 51的确认报文。客户端收到后，检查发现这个报文并不是自己期望的Ack Num = 101的报文，所以发送了RST报文来终止连接。一段时间后，服务器收到了SYN报文2，返回确认报文Ack Num = 101。客户端收到后再次确认，建立连接成功。 所以在上面这个过程中，第三次握手让客户端可以判断当前连接是否是旧的重复连接，从而选择终止连接或成功建立连接。 如果是两次握手，客户端就不能判断是否是重复连接。因为第二次握手时，服务器已经为连接分配资源，客户端只能选择建立连接, 而这个连接是没有任何用处的。这样会导致双方资源的浪费。 同步双方初始序列号 TCP通过序列号维持可靠传输。通过序列号：接收方可以丢弃重复的包；接收方可以根据序号按序接收；可以标识发出的包中，有哪些被对方成功接收。客户端发送携带初始序列号的SYN报文，需要服务端返回ACK应答，表示客户端的初始序列号成功创建滑动窗口。反之，服务端的初始序列号同样需要客户端的确认。这样的两次来回，才能确认双方的初始序列号都可以同步。在这来回的四次中，服务端确认ACK，和服务端发送自己的初始序列号可以合并在一个报文中，因此就简化成了三次握手。 避免资源浪费 如果只有两次握手，当客户端的SYN报文在网络中阻塞时，客户端没有收到来自服务器的ACK报文，就会重新发送SYN。一段时间后，当服务器接收到了SYN报文，由于没有第三次握手，服务器不清楚客户端是否收到了自己的确认报文，所以只能对每个SYN都建立一个连接。这样会导致服务器建立多个重复冗余的连接，造成资源浪费。 四次挥手 过程 第一次挥手 客户端发送FIN报文，标志位FIN=1，序列号为Seq Num为之前对方最后传过来的数据的最后一个字节的序号+1，假设Seq Num = u. 客户端停止发送数据，进入FIN-WAIT-1状态。 第二次挥手 服务端收到FIN报文后，发出确认报文，标志位ACK=1，确认序号Ack Num = u + 1，假设自己的序列号Seq Num = v。 服务端进入CLOSE-WAIT状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态。即客户端已经没有数据要发送了，但是服务器若发送数据，或者有数据包还在网络中，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。 客户端收到服务器的确认请求后，进入FIN-WAIT-2状态，等待服务器发送FIN报文，期间继续接收服务器发送的数据包。 第三次挥手 一段时间后，服务器发送完最后的数据包，就向客户端发送FIN报文，标志位FIN=1, Ack Num = u+1, 由于CLOSE-WAIT状态可能又发送了一些数据，假设此时Seq Num = w。服务器进入LAST-ACK状态，等待客户端最后的确认。 第四次挥手 客户端收到FIN报文后，发出确认报文，标志位ACK=1，Ack Num = w+1，Seq Num = u + 1. 客户端进入TIME-WAIT状态。TCP连接并未立即释放，需要等待 2*MSL的时间，然后释放资源，进入CLOSED状态。 服务端收到确认报文后，立即进入CLOSED状态。释放资源。因此服务端结束连接的时间比客户端稍早一些。 常见问题 为什么要挥手四次？ 每个方向都需要一个FIN和ACK，所以需要四次。在三次握手中，服务端的确认ACK和建立连接SYN合并在一个报文。但在四次挥手中，由于客户端发送FIN仅代表不再发送数据，但是还能接收数据；服务端对FIN进行回应后，可能还有数据需要发送，需要等全部发完后才能发送FIN报文来表示服务端同意关闭连接。因此，服务器确认ACK和发送FIN需要分开发送，从而比三次握手多了一次。 为什么TIME_WAIT状态等待2 * MSL 的时间？ MSL是报文最大生存时间，超过这个时间报文将被丢弃。如果服务端没有收到最后来自客户端的ACK报文，超时后服务端会重新发送FIN报文。客户端收到FIN后，会重新发送ACK报文给服务端。双方一去一回的时间为2MSL。这样，客户端可以在2 MSL 的时间内收到重传的FIN报文，然后发出ACK，重置2 MSL的计时器。超过2 MSL后，则说明不再有服务端重传的FIN报文，最后的ACK报文已被服务端接收，可以关闭连接了。 需要TIME_WAIT状态的原因 保证连接正确关闭 TIME-WAIT - represents waiting for enough time to pass to be sure the remote TCP received the acknowledgment of its connection termination request. RFC 793指出，TIME_WAIT的作用是等待足够的时间来确保服务端接收到最后的ACK。 如果没有TIME_WAIT状态，当客户端最后发送的ACK报文在网络中丢失，而客户端直接进入CLOSED状态。服务端将永远无法收到最后的ACK，那么服务端则会一直处在LAST_ACK状态。 当客户端想再次建立连接，发送SYN报文后，服务端由于一直处在LAST_ACK状态，会发送RST报文给客户端，连接建立的过程就会被终止。 上面说过，将等待时间设置为2 * MSL可以保证服务端能够正常收到最后的ACK报文。 防止新的连接收到旧连接的数据包 如果没有TIME_WAIT状态，当在关闭连接之前发送的数据包1在网络中延迟，然后连接正常被关闭。这时如果双方有相同端口的新的TCP连接建立，而恰好来自旧的连接的数据包1抵达，那么就有可能将这个来自旧连接的数据包接收，从而造成错乱。 将TIME_WAIT设置成2 * MSL，保证了两个方向的数据包都已经超时丢弃，使得旧连接的数据包在网络中自然消失，从而避免了新的连接收到旧连接的数据包的情况。 TIME_WAIT状态等待时间过长有什么危害 内存占用。TCP连接的资源迟迟无法释放。如果是服务器（服务器主动发起的断开请求），可能会导致线程池占满，处理不过来新的连接。 端口占用。一个TCP连接至少消耗一个本地端口。当处在TIME_WAIT状态的连接过多，占满了端口，将导致无法创建新的连接。 如果已经建立了连接, 但是客户端突发故障了怎么办? TCP设有一个保活计时器，客户端如果出现故障，服务器不能一直等下去浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若2小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-22 10:10:10 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/udp.html":{"url":"network/udp.html","title":"UDP详解","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 UDP详解 特点 报文 首部 数据 UDP和TCP的区别 UDP详解 UDP是运输层的用户数据报协议，基于UDP的应用层协议有DNS，RIP等。 特点 无需建立连接。发送方与接收方在传输数据之前不建立连接，发送方只是简单的把数据发送到网络上；接收方把收到的数据报放在队列中，供应用进程读取。UDP不会产生建立连接的时延，因此DNS采用UDP。 无连接状态。TCP为保证可靠运输需要维护连接状态，包括序列号，窗口大小，缓存等参数。UDP不需要维护连接状态，也不需要跟踪这些参数。 尽最大努力交付。应用进程只要将数据交给UDP，UDP就会立刻封装成数据报发送到网络中。吞吐量不受拥塞控制算法的调节，只受应用软件生成数据的速率、传输带宽、 源端和终端主机性能的限制。 不可靠运输。UDP只是提供了运输层最基本的功能。没有确认应答、重传、拥塞控制、缓冲窗口等保证可靠运输的手段。简单网络管理协议SNMP使用UDP作为运输层，因为在网络重压情况下，可靠的、有拥塞控制的数据传输变得难以实现。 面向报文。UDP将应用进程的报文，在添加首部后就向下交付给IP层。既不拆分，也不合并，而是保留这些报文的边界。 因此，应用程序需要选择合适的报文大小。 分组首部开销小。UDP头只有8个字节。 报文 首部 16位源端口号：UDP使用（目的IP，目的端口号）二元组来唯一标识进程。有相同的目的IP和目的端口号的报文，会被同一个套接字接收，并定向到相同的应用进程。在这个过程源端口号是没用的。但如果接收方要回复一个报文给发送方时，就可以直接将报文中的源端口号提取出来，作为目的端口号。 16位目的端口号：多路分解时用于定位目的进程。 16位长度：包括首部的UDP报文长度，以字节为单位。 16位检验和：UDP检验和提供了差错检测功能，不能进行差错恢复。一些UDP会将错误报文丢弃，另一些UDP会警告应用进程。 虽然链路层也提供了差错检测，但不能保证源与目的之间所有的链路都提供差错检测。另外，即使报文段被正确传输，在报文段存储在某路由器的内存中时，也可能出现比特差错。因此UDP提供了端到端的差错检测。 发送方的UDP对全部的16比特字求和，溢出时回卷。然后将结果取反，作为检验和。比如，下面的数据： 按16位排列 0110011001100000 0101010101010101 1000111100001100 前两行求和得到 1011101110110101 与第三行求和： 1000111100001100 + ————————————————— 溢出回卷，得到 0100101011000010 将结果取反 1011010100111101 于是就得到了检验和1011010100111101。接收方将包括检验和的4个16比特字按同样的方式求和。如果结果全是1，则分组没有差错；如果结果中出现了0，则分组出现了差错。 数据 对于DNS，数据要么包含一个查询报文，要么包含一个响应报文。对于流媒体应用，数据可以是媒体抽样。 UDP和TCP的区别 TCP面向连接，UDP是无连接的。 TCP对系统资源的要求较多，UDP较少。由于UDP是无连接的，不需要保存连接的参数。TCP要为每个对等方分配资源建立连接，而UDP不需要，UDP只用一个套接字来接收和发送报文。 TCP是面向字节流的，UDP是面向报文的。TCP的发送和接收都是将字节数据暂存到缓冲区，在合适的时间发送或交付给上层。UDP是将来自上层的数据直接打包成报文，立即发送。 TCP提供可靠传输，包括确认应答机制，重传机制，流量控制，拥塞控制等。UDP不提供，可能会丢包。当然，开发者可以在应用层实现这些机制，从而可以进行可靠通信，而无需被TCP拥塞机制约束住传输速率。 也因此，UDP的报文比TCP简单。UDP头只需要8字节，TCP头有20-60字节。 由于有基于序列号的确认应答机制，TCP能保证数据的顺序。而UDP不提供，开发者只能在应用层自己实现这个功能。 TCP对网络环境有拥塞控制机制，UDP没有。拥塞控制能保持网络的可用性，而降低传输的实时性能。在一些流媒体的场景比如视频会议、音频等，应用可以容忍一些分组的丢失，而传输的实时性则更加重要，UDP往往更适合这些应用。然而，如果网络中每个用户都传输高比特率视频，而没有任何的拥塞控制，路由器中就会有大量的分组溢出，以至于几乎没有UDP分组能成功传输到目的地。此外，路径上某处由UDP造成的大量丢包，会导致TCP发送方减小发送速率，甚至挤垮TCP会话。所以提出了另外的一些机制，如DCCP，让所有的数据源（包括UDP）执行自适应的拥塞控制。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-30 12:51:39 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/reverseproxy.html":{"url":"other/reverseproxy.html","title":"Docker 安装 Nginx 并实现反向代理","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 Docker 安装 Nginx 并实现反向代理 安装 Nginx 镜像 拉取镜像 创建实例 创建关键目录映射点 反向代理 Docker 安装 Nginx 并实现反向代理 安装 Nginx 镜像 拉取镜像 docker pull nginx 查看镜像 docker images 创建实例 docker run --name nginx-test -p 80:80 -d nginx docker start nginx-test 浏览器访问服务器ip，运行nginx欢迎页面 创建关键目录映射点 本地创建文件夹 html: nginx存储网页的目录 logs：日志目录 conf：配置文件目录 mkdir -p nginx/html nginx/logs nginx/conf 将刚才创建的nginx容器的配置文件拷贝到本地 docker cp nginx-test:/etc/nginx ~/nginx/conf 创建新的nginx容器 docker run -d -p 80:80 --name nginx -v ~/nginx/html:/usr/share/nginx/html -v ~/nginx/logs:/var/log/nginx -v ~/nginx/conf:/etc/nginx nginx docker start nginx 反向代理 反向代理就是将访问本机的数据代理转发到本机的其他端口。比如，一个网站在4000端口上，而浏览器默认访问而的是80端口。就可以用nginx将访问80端口的数据转发到4000端口上，然后浏览器直接访问80端口就可以看到网站了。 所以要先知道要反向代理的服务的地址。由于我们要代理的是容器，先查看容器的ip docker inspect 容器名 在最后的Networks下看到IPAddress 编辑conf/conf.d/default.conf，修改proxy_pass 为目标容器的ip和端口号 location / { #root /usr/share/nginx/html; #index index.html index.htm; proxy_pass http://172.17.0.2:4000; } 访问浏览器，成功跳转到目标网页 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-23 15:24:35 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/process-from-URL-to-response.html":{"url":"network/process-from-URL-to-response.html","title":"从输入URL到获得页面请求的全过程","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 从输入URL到获得页面请求的全过程 输入URL 域名解析 建立连接 应用层 运输层 网络层 链路层 服务器处理 浏览器处理 从输入URL到获得页面请求的全过程 输入URL 向地址栏中输入URL，浏览器会先检查URL，包括去除空格，非法字符等。 假如URL为：http://www.bourbon17.site/network/tcp.html 把URL分成协议、网络地址、资源路径三部分 协议：从该计算机获取资源的方式，有HTTP、HTTPS、FTP等，不同协议有不同的通讯内容格式，如果没有，则自动补全http:// 网络地址：指连接网络上的哪一台计算机，可以是域名、IP地址，可以包括端口号。如：www.bourbon17.site 资源路径：指从服务器上获取哪一项资源。如 /network/tcp.html 域名解析 如果URL中的网络地址直接是IP+端口号（如果省略端口号，则是HTTP默认80端口），就可以直接建立连接；如果是域名，就需要先进行域名解析，就是根据域名寻找对应的IP地址。 假如解析www.bourbon17.site，浏览器会依次进行以下查找： 从浏览器缓存里查找对应的IP，因为浏览器会缓存DNS记录一段时间 如果没找到，从系统hosts文件中查找 如果没找到，从路由器缓存查找，路由器通常有自己的DNS缓存 如果没找到，发送DNS请求到本地DNS服务器，然后从本地DNS缓存差找。本地DNS服务器通常与主机在同一个局域网中，或者相隔不过几个路由器 如果没找到，本地DNS服务器开始进行递归或迭代搜索。从根DNS服务器开始，顶级域服务器，权威DNS服务器······依次查找。比如查找www.cqu.edu.cn的IP地址：先从根DNS服务器查找，然后去.cn顶级域服务器，然后去.edu二级域名服务器，然后.cqu······这样从域名的右边向左依次搜索，最终找到了对应的IP地址。前面的DNS服务器返回的都是接下来应该查询的DNS服务器的IP地址，最终的权威服务器将返回域名对应的IP。当然，每个DNS服务器都设有缓存，如果缓存命中，就可以直接返回结果。 建立连接 应用层 将域名转换成IP地址后，就可以正常进行HTTP请求了，发送HTTP报文。 运输层 HTTP使用TCP作为运输层协议，提供端到端的可靠数据传输。 首先通过三次握手与服务器建立连接。 然后将应用层的数据读入缓存，即HTTP报文。按MSS分割成若干的TCP报文，发送到网络层。 之前的DNS使用UDP，直接将报文发送到网络层。 网络层 网络层通过IP地址找到对应的主机。 首先将运输层报文套上IP报头，包括源IP、目标IP、TTL、首部检验和等，就成了IP数据报。 然后计算机将目标IP地址与子网掩码进行与运算，来判断是否目标IP与本机是否在同一子网下。如果在同一子网，就可以直接通信；如果不在，说明目标IP在外部的网络中，就需要通过网关将数据报发送出去。 从网关转发出口后，通过路由器一步一步的跳转。路由器内部维护了路由表，包括目标地址、子网掩码、网关、 接口等几项。路由器将目标IP与表中每个条目的子网掩码进行与运算，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续尝试下个条目。如果没有能匹配的，就选择默认路由0.0.0.0。 然后路由器检查该条目的网关一项。如果网关的内容是一个IP地址，说明这时下一跳的路由器IP地址；如果网关为空，说明该条目的目标地址就是最终的目的IP了。然后将数据报转发到条目对应的接口上就可以转发出去了。 链路层对传输单元的大小有限制，一个链路层帧能承载的最大数据量叫最大传输单元MTU。当MTU比IP数据报的长度要小，就需要对IP数据报分片，分出的片也要加上IP报头，变成更小的IP数据报。由于每个链路的MTU可能不同，在MTU变小时，路由器也会将IP数据报继续分片。但路由器在收到众多分片后并不会组装，只有最终的目标设备才会组装所有的IP分片。 链路层 链路层提供了网络路径上节点间的可靠传输。链路层上的设备通过MAC地址唯一标识，即物理地址。每张网卡，路由器的每个端口都有独特的MAC地址。 同样的，在IP数据报外面套上MAC头部，包括源MAC地址、目标MAC地址等，就成了帧。发送方的MAC地址可以直接从设备读取；接收方的MAC地址需要通过路由表中查询结果的IP得到。从IP到MAC的转换使用ARP协议。ARP会先检查缓存是否记录了IP对应的MAC地址。如果缓存里没有，就在网络中广播，询问这个IP对应的MAC是谁，然后对应IP的设备会回应自己的MAC，这样本机就得到了目标IP对应的MAC了。 linux使用arp -a查看ARP缓存 链路层的帧只提供节点到节点的传输，比如从计算机到路由器，路由器到路由器。帧从源MAC地址对应的网卡发送到网络，然后到达下一跳路由器后，就会解包。路由器会检查这个帧的MAC地址是否属于自己，如果不是，就直接丢弃。解包后，MAC的任务就完成了，路由器得到了IP数据报，才能进行网络层的转发等操作。 在网络传输的过程中，源IP和目标IP始终是不会变的，一直变化的是MAC地址，因为需要MAC地址在以太网内进行两个设备之间的传输。 服务器处理 服务器最终收到了数据。从链路层依次向上分解，组装若干IP分片，再分解出运输层报文，通过端口号找到进程，存到TCP连接的缓存中。当所有TCP报文都收到后，TCP将报文内容按序组装，得到浏览器发来的HTTP报文，交付给网站的后台程序。 后台解析HTTP请求，通过资源路径找到对应的资源，或者找到对应的处理函数。然后解析请求中的参数、请求体等，做出相应的处理（查询数据库，组装HTML等）。将数据写入HTTP response，按同样的方式经过网关、路由器等返回给浏览器。 浏览器处理 然后浏览器收到了来自服务器的响应，内容就是URL对应的HTML页面。浏览器在解析HTML时，会自上而下加载，并在加载过程中进行解析渲染，生成DOM节点。在解析过程中，如果遇到请求外部资源时，如图片、外链的CSS等，会继续发送请求。请求过程是异步的，并不会影响HTML的加载。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-31 14:24:00 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"db/mysql-transaction.html":{"url":"db/mysql-transaction.html","title":"MySQL事务","keywords":"","body":"MySQL 事务 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-02-02 15:39:30 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"db/mysql-index.html":{"url":"db/mysql-index.html","title":"MySQL索引","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 MySQL 索引 普通索引 创建索引 修改表结构(添加索引) 创建表的时候直接指定 删除索引 唯一索引 创建索引 修改表结构 创建表的时候直接指定 主键索引 组合索引 全文索引 注意事项 设计 使用 索引的存储类型 B-树 B+树 索引查询 聚簇索引 哈希索引 索引的优点 索引的缺点 MySQL 索引 索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。当对一个大表使用where子句查询一个非主键时，查询速度会很慢，因为需要遍历整个表才能查找到这个值。这时如果建立了索引，就可以像主键那样直接找到值，大幅提升查询速度。 索引分为单列索引和组合索引。 单列索引，即一个索引只包含单个列，一个表可以有多个单列索引。 组合索引，即一个索引包含多个列。 普通索引 最基本的索引，没有任何限制。 创建索引 CREATE INDEX indexName ON mytable (username(length)) 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。 修改表结构(添加索引) ALTER table mytable ADD INDEX indexName(username(length)) 创建表的时候直接指定 CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX [indexName] (username(10)) ); 建表时，usernname长度为 16，这里用 10。这是因为一般情况下名字的长度不会超过10，这样会加速索引查询速度，还会减少索引文件的大小，提高INSERT的更新速度。 删除索引 DROP INDEX [indexName] ON mytable; 唯一索引 它与前面的普通索引类似，区别是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。 创建索引 CREATE UNIQUE INDEX indexName ON mytable(username(length)) 修改表结构 ALTER table mytable ADD UNIQUE [indexName] (username(length)) 创建表的时候直接指定 CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, UNIQUE [indexName] (username(length)) ); 主键索引 主键索引也是特殊的唯一索引。主键在物理层面上只有两个用途： 惟一地标识一行。 作为一个可以被外键有效引用的对象。 主键一定是唯一性索引，但主键并不允许有空值。一个表只能有一个主键，但可以有多个唯一索引。 主键是逻辑键，而索引是物理键。一般在建表的时候指定主键，同时在物理层面创建主键索引。 CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, PRIMARY KEY(ID) ); 与之类似的，也有外键索引。如果为某个外键字段定义了一个外键约束条件，MySQL就会定义一个内部索引来帮助自己以最有效率的方式去管理和使用外键约束条件。 组合索引 类比于主键可以包含多个列，索引也可以包含多个列。这样的索引称为组合索引。 CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, city VARCHAR(50) NOT NULL, age INT NOT NULL ); 比如，在上面的表中建立一个组合索引： ALTER TABLE mytable ADD INDEX name_city_age (name(10),city,age); 建立这样的组合索引，其实是相当于分别建立了三组组合索引：(usernname,city,age)，(usernname,city)，(usernname)。 为什么没有 (city,age)这样的组合索引呢？这是因为MySQL组合索引“最左前缀”的结果。简单的理解就是只从最左面的开始组合, 并不是只要包含这三列的查询都会用到该组合索引。下面的几个SQL就会用到这个组合索引： SELECT * FROM mytable WHERE username=\"admin\" AND city=\"郑州\" SELECT * FROM mytable WHERE username=\"admin\" 而下面的则不会用到： SELECT * FROM mytable WHERE age=20 AND city=\"郑州\" SELECT * FROM mytable WHERE city=\"郑州\" 组合索引更像是依次检索username -> city -> age，逐层的确定出一行。因为组合索引在底层存储中保证了依次有序，非常适合上面这类查询。 全文索引 对于查询文本中的关键词，可以建立全文索引。但InnoDB内部并不支持中文、日文等，因为这些语言没有分隔符。可以使用插件辅助实现中文、日文等的全文索引。与使用like '%word%'相比，全文索引效率更高。 CREATE FULLTEXT INDEX indexName ON mytable(column); select * from mytable where match(column) against('word'); match() 函数中指定的列必须和全文索引中指定的列完全相同，否则就会报错，这是因为全文索引不会记录关键字来自哪一列。如果想要对某一列使用全文索引，请单独为该列创建全文索引。此外，innodb的全文索引只会对长度大于3小于84的词建立索引。 注意事项 设计 索引字段尽量使用数字型（简单的数据类型）。在处理查询时，字符串类型会逐个比较每个字符，而对于数字类型只需要比较一次。 尽量不要让字段的默认值为NULL。在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。在设计时，应该用0、一个特殊的值或者一个空串来代替NULL。 使用前缀索引并且保证较高的索引选择性。对字符串或文本进行索引，应该指定索引的前缀长度。目的是用较短的存储空间就可以索引出更多的值。 比如，用一个CHAR(255)的列来存储用户名，通常在前20个字符内就可以把搜索范围缩小到几条数据，这样建立一个短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作；而如果CHAR(255)的列在前10-20个字符内多数值是相同的，那就不要对整个列进行索引。 关键在于，要选择足够长的前缀来保证较高的索引选择性，同时又不能太长。索引选择性是指不重复的索引值和数据表中的记录总数的比值。索引的选择性越高，查找时就可以过滤掉更多的行。唯一索引的选择性是1. 使用唯一索引。上一点说到，唯一索引的选择性最高，索引的效果最好。 使用组合索引代替多个列索引。 注意重复和不使用的索引。MySQL允许在相同的列上创建多个索引，无论是有意还是无意的。大多数情况下不需要使用冗余索引。对于重复和不使用的索引：可以直接删除这些索引。因为这些索引需要占用物理空间，并且也会影响更新表的性能。 使用 如果要对文本进行搜索，使用全文索引，而不是like like不要以通配符开头。以通配符%和_ 开头作为查询时，MySQL不会使用索引。 不要在列上进行运算，也不要做函数参数。比如下面两个查询都无法使用索引： select actor_id from sakila.actor where actor_id+1=5; select ... where TO_DAYS(CURRENT_DATE) - TO_DAYS(date_col) 尽量不要使用NOT IN, <>, != 操作。可以将NOT IN用NOT EXISTS代替，将a<>0用a0代替 尽量避免在 where 子句中使用 or 来连接条件。用 or 分割开的条件， 如果 or 前的条件中的列有索引， 而后面的列中没有索引， 那么涉及到的索引都不会被用到。 组合索引的使用要遵守“最左前缀”原则。对于一个组合索引(a,b,c)：查询必须从索引左边的列开始，比如查询（a,b）。不能跳过某一列，比如查询(a,c)是不行的。不能使用索引中范围条件右边的列，比如WHERE a=123 AND b LIKE 'cde%' AND c='sdgf'只能使用(a,b)的索引，因为LIKE是范围查询。 如果列类型是字符串，那么一定记得在 where 条件中把字符常量值用引号 ' ' 引起来。否则的话即便这个列上有索引，MySQL 也不会用到的，因为MySQL 默认把输入的常量值进行转换以后才进行检索。 索引的存储类型 B-树 传统用来搜索的平衡二叉树有很多，如 AVL 树，红黑树等。这些树在一般情况下查询性能非常好，但当数据非常大的时候它们就无能为力了。原因当数据量非常大时，大部分数据只能存放在磁盘上，只有需要的数据才加载到内存中。磁盘读取时间远远超过了数据在内存中比较的时间，这时程序大部分时间会阻塞在磁盘 IO 上。我们需要尽可能的减少磁盘 IO 次数来提升性能。 平衡二叉树是通过旋转来保持平衡的，而旋转是对整棵树的操作，若部分加载到内存中则无法完成旋转操作。其次平衡二叉树的高度相对较大为 log n（底数为2），这样逻辑上很近的节点实际可能非常远，无法很好的利用磁盘预读（局部性原理），因此像AVL树，红黑树这类平衡二叉树从设计上无法迎合磁盘。 空间局部性原理：如果一个存储器的某个位置被访问，那么将它附近的位置也会被访问。 B-树是专门为外部存储器设计的，如磁盘，它对于读取和写入大块数据有良好的性能，所以一般被用在文件系统及数据库中。B-树也是平衡树，相比与平衡二叉树，B-树允许每个节点有更多的子节点。它有以下特点： 所有键值分布在整颗树中（索引值和具体data都在每个节点里）； 任何一个关键字出现且只出现在一个结点中； 搜索有可能在非叶子结点结束，最好情况O(1)就能找到数据； 在关键字全集内做一次查找, 性能逼近二分查找； B-树将整个表范围分割为多个区间，区间越多，定位数据越快越精确，节点也越大。新建节点时，直接申请页大小的空间（磁盘存储单位是按 block 分的，一般为 512 Byte。磁盘一次读取若干个 block 称为一页，具体大小和操作系统有关），计算机内存分配是按页对齐的，这样一个节点只需要一次磁盘 IO。 B+树 MySQL的innodb采用B+树作为底层数据结构。B+树是B-树的变体，也是一种多路搜索树, 它与 B-树的不同之处在于: 所有data存储在叶子节点，非叶子节点并不存储真正的 data 为所有叶子结点增加了一个指针，指向下一个叶子节点 B+树的内节点并不存储data，所以一般B+树的叶子节点和内部节点大小不同，而B树的每个节点大小是相同的，为一页。另外，B+树查询的时间复杂度固定为log n（底为分叉数），而B树的查询时间复杂度与key在树的位置有关。 B+树可以很好的利用空间局部性原理。由于B+树的叶子节点的数据都是使用链表连接起来的，而且他们在磁盘里是顺序存储的，所以当读到某个值的时候，磁盘预读原理就会提前把这些数据都读进内存，使得范围查询和排序都很快。在范围查询时，比如查询500-1000之间的节点，利用磁盘预读原理可以减少磁盘IO次数。 由于B+树的内部节点只存储索引的副本和指针，不存储data，所以在同样都是读取一页的IO中，B+树能读取到的索引值多于B树。从而减少了查询需要的IO次数。 使用B+树作为索引能让数据库的查询速度上升，而使写入数据的速度下降。因为平衡树这个结构必须一直维持在一个正确的状态，增删改数据都会改变平衡树各节点中的索引数据内容，破坏树结构。因此，在每次改变数据时，DBMS必须去重新梳理树的结构以确保它的正确，这会带来不小的性能开销，这也是索引会给查询以外的操作带来副作用的原因。 索引查询 B+树可以对，>=，BETWEEN，IN，以及不以通配符开始的LIKE使用索引。 B+树可以进行以下查询： 匹配全值：对索引中的所有列都指定具体的值。例如，上图中索引可以帮助你查找出生于1960-01-01的Cuba Allen。 匹配最左前缀：你可以利用索引查找last name为Allen的人，仅仅使用索引中的第1列。根据最左前缀原则，查询必须从最左边的列开始，并且不能跳过某一索引列。比如，不能直接查询first name，也不能查询(last name, date) 匹配列前缀：例如，你可以利用索引查找last name以J开始的人，这仅仅使用索引中的第1列。 匹配值的范围查询：可以利用索引查找last name在Allen和Barrymore之间的人，仅仅使用索引中第1列。 匹配部分精确而其它部分进行范围匹配：可以利用索引查找last name为Allen，而first name以字母K开始的人。但使用范围条件后，它后面的列将无法使用索引。 仅对索引进行查询：如果查询的列都位于索引中，则不需要再多一次I/O回读元组。索引的叶子节点中已经包含要查询的数据，那么就没有必要再回表查询了，如果索引包含满足查询的所有数据，就称为覆盖索引。比如，select date from people where last_name='Allen' and first_name='Cuda';所需要的date 已经包含在了索引中，所以不需要再从真正的数据节点里读取了。 聚簇索引 当建表时，我们给表加上了主键，这时表在磁盘上的存储结构变成了B+树，整个表的索引就是主键。这就是聚簇索引。一个表只能有一个主键，一个表也只能有一个聚簇索引，因为主键的作用就是把表的存储格式转换成树状的索引。如果不指定主键，InnoDB会用一个具有唯一且非空值的索引来代替。如果不存在这样的索引，InnoDB会定义一个隐藏的主键，然后建立聚簇索引。 一个表只能有一个聚簇索引，用来存储数据。但一个表可以有多个索引，显然不能为每个索引树都复制一份数据，于是就有了非聚簇索引（二级索引）。和聚簇索引一样，非聚簇索引也用B+树作为存储结构，也用索引列的字段作为节点值。不同的是，非聚簇索引的叶子节点存放的是数据行的主键，而不是数据行本身。 每次给表新建一个索引时，索引列中的值都会被复制出来一份，用于生成新的非聚簇索引。增删改数据时，这些的索引树也都会更新。因此， 给表添加索引，会增加表的体积， 占用磁盘存储空间。 在查询非主键索引时，数据库会先通过对应的非聚簇索引找到对应数据的主键值，然后用主键去查询聚集索引，得到数据。一共进行了2次B+树查询。 无论以任何方式查询，最终都会用主键通过聚簇索引来定位到数据，聚簇索引（主键）是通往真实数据所在的唯一路径。 然而还有另外一种特殊的方法可以不使用聚簇索引就能得到数据，即覆盖索引。建立一个索引时，索引列的数据会复制一份到索引树中。如果建立的是组合索引，树的节点中就会有多个列值。比如我们建立一个组合索引 (name, age)，树中的节点也应当包含这两个字段的值。按最左前缀原则，我们可以只对name进行查询。当查询select age from mytable where name='xxx';时，如果在索引树中通过name定位到了唯一的索引项，而我们所需要的age字段也在索引项里，那么我们就可以直接返回索引项中的age字段，而不需要再获取主键、再查聚簇索引。通过这种覆盖索引直接查找的方式，可以省略覆盖索引查找的后面两个步骤，大大的提高了查询性能。 哈希索引 MySQL中，只有Memory存储引擎显示支持hash索引。哈希索引基于哈希表实现，只有精确索引所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据的指针。 Hash索引有以下一些限制： 由于索引仅包含哈希码和记录指针，所以，MySQL不能通过使用索引避免读取记录，即每次使用哈希索引查询到记录指针后都要回读元组查取数据。 不能使用hash索引排序。 Hash索引不支持键的部分匹配，因为是通过整个索引值来计算hash值的。 Hash索引只支持等值比较，例如使用=，IN( )和。对于WHERE price>100并不能加速查询。 访问Hash索引的速度非常快，除非有很多哈希冲突（不同的索引列值却有相同的哈希值）。当出现哈希冲突的时候，存储引擎必须遍历链表中所有的行指针，逐行进行比较，直到找到所有符合条件的行。 如果哈希冲突很多的话，一些索引维护操作的代价也会很高。当从表中删除一行时，存储引擎要遍历对应哈希值的链表中的每一行，找到并删除对应行的引用，冲突越多，代价越大。 InnoDB引擎有一个特殊的功能叫做自适应哈希索引。当InnoDB注意到某些索引值被使用得非常频繁时，它会在内存中基于缓冲池中的B+树索引上再创建一个哈希索引，这样就使B+树索引也具有哈希索引的一些优点，比如快速的哈希查找。启用自适应哈希索引后，读和写性能可以提高2倍，对于辅助索引的连接操作，性能可以提高5倍。 索引的优点 索引大大减小了服务器需要扫描的数据量 索引可以帮助服务器避免排序和临时表 索引可以将随机IO变成顺序IO 索引对于InnoDB（对索引支持行级锁）非常重要，因为它可以让查询时锁更少的元组。在MySQL5.1和更新的版本中，InnoDB可以在服务器端过滤掉行后就释放锁。但在早期的MySQL版本中，InnoDB直到事务提交时才会解锁。对不需要的元组的加锁，会增加锁的开销，降低并发性。而索引能够减少InnoDB访问的元组数。InnoDB在二级索引上使用共享锁（读锁），但访问主键索引需要排他锁（写锁）。 索引的缺点 虽然索引大大提高了查询速度，同时却会降低增删改的速度。因为MySQL不仅要修改数据，还要修改索引文件。 建立索引会增加索引文件占用的磁盘空间。如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快。MySQL里同一个数据表里的索引总数限制为16个。 如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。 对于非常小的表，大部分情况下简单的全表扫描更高效； Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-02-02 15:39:30 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}